GFA Audit for:orghbdamsaccArithAvg
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.0.data:[0.0, {"1.0": {"1.0": 760, "0.0": 149}, "0.0": {"0.0": 250, "1.0": 160}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.1.data:[0.1, {"1.0": {"1.0": 741, "0.0": 168}, "0.0": {"1.0": 208, "0.0": 202}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.2.data:[0.2, {"1.0": {"1.0": 705, "0.0": 204}, "0.0": {"1.0": 192, "0.0": 218}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.3.data:[0.30000000000000004, {"1.0": {"1.0": 736, "0.0": 173}, "0.0": {"1.0": 240, "0.0": 170}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.4.data:[0.4, {"1.0": {"1.0": 804, "0.0": 105}, "0.0": {"1.0": 286, "0.0": 124}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.5.data:[0.5, {"1.0": {"1.0": 808, "0.0": 101}, "0.0": {"1.0": 298, "0.0": 112}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.6.data:[0.6, {"1.0": {"0.0": 546, "1.0": 363}, "0.0": {"1.0": 190, "0.0": 220}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.7.data:[0.7, {"1.0": {"0.0": 529, "1.0": 380}, "0.0": {"1.0": 189, "0.0": 221}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.8.data:[0.7999999999999999, {"1.0": {"0.0": 527, "1.0": 382}, "0.0": {"1.0": 195, "0.0": 215}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_0.9.data:[0.8999999999999999, {"1.0": {"0.0": 501, "1.0": 408}, "0.0": {"1.0": 210, "0.0": 200}}]
Dark-Reaction-DT/orghbdamsaccArithAvg.audit.test.repaired_1.0.data:[0.9999999999999999, {"1.0": {"1.0": 909}, "0.0": {"1.0": 410}}]

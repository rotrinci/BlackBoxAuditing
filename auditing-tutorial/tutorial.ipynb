{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example\n",
    "\n",
    "First, let's load the libraries and example data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import BlackBoxAuditing as BBA\n",
    "\n",
    "import pylab\n",
    "%matplotlib inline\n",
    "\n",
    "from BlackBoxAuditing.model_factories import SVM, DecisionTree, TensorFlow\n",
    "german_data = BBA.load_data(\"german\")\n",
    "ricci_data = BBA.load_data(\"ricci\")\n",
    "adult_data = BBA.load_data(\"adult\")\n",
    "synthetic_data = BBA.load_data(\"sample\")\n",
    "dark_data = BBA.load_data(\"DRP\")\n",
    "compass_data = BBA.load_data(\"Compass\")\n",
    "hof_data = BBA.load_data(\"HOF\")\n",
    "housing_data = BBA.load_data(\"Housing\")\n",
    "disease_data = BBA.load_data(\"Disease\")\n",
    "mutations_data = BBA.load_data(\"Mutations\")\n",
    "student_data = BBA.load_data(\"Student\")\n",
    "student_data_v2 = BBA.load_data(\"Student-V2\")\n",
    "loan_data = BBA.load_data(\"Loan\")\n",
    "mhs_data = BBA.load_data(\"MHS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the filename and mode ('w' for writing)\n",
    "filename = 'german.csv'\n",
    "\n",
    "# Open the file in write mode and specify newline='' to prevent extra line breaks\n",
    "with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the header row if needed\n",
    "    writer.writerow(['First Name', 'Last Name', 'Age'])\n",
    "    \n",
    "    # Write each tuple as a row in the CSV file\n",
    "    for row in german_data:\n",
    "        writer.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create an \"Auditor\" object, which will run the model with obscured features in order to check for potential influence. The `Auditor` object needs to know about how to build a model, and so it takes a `model` field. This is a `ModelFactory` instance, and our library provides you with a few predefined choices about this. (TBD: do we want to add a section about how to create a new `ModelFactory` subclass?)\n",
    "\n",
    "It takes a bit of time for this to run (a few seconds per attribute in our laptop):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import BlackBoxAuditing as BBA\n",
    "\n",
    "import pylab\n",
    "%matplotlib inline\n",
    "\n",
    "from BlackBoxAuditing.model_factories import SVM, NeuralNetwork\n",
    "print(type(SVM))\n",
    "print(type(NeuralNetwork))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = TensorFlow\n",
    "auditor(adult_data, output_dir=\"adult-audit-output-NN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audits_data = auditor._audits_data\n",
    "print(audits_data[\"rep_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BlackBoxAuditing import find_contexts\n",
    "auditor.find_contexts('Race', output_dir=\"ricci_context_output\", beam_width=10, min_covered_examples=1, max_rule_length=5, by_original=True, epsilon=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our auditing technique always works relatively to some existing model, and some measure of accuracy. The list of ranked features can be different depending on the measure used, and that's sometimes important. Often, however, they tend to correlate fairly strongly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcr_data = pd.read_csv(\"german-audit-output-SVM/BCR.png.data\")\n",
    "acc_data = pd.read_csv(\"german-audit-output-SVM/accuracy.png.data\")\n",
    "\n",
    "def compute_influence(dataset):\n",
    "    return (dataset.iloc[0][1:] - dataset.iloc[-1][1:])\n",
    "\n",
    "bcr_influence = compute_influence(bcr_data)\n",
    "acc_influence = compute_influence(acc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.plot(acc_influence, bcr_influence, 'ko')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading your own data\n",
    "\n",
    "In order to use your own data with our auditing, you'll probably need to make a few conversions. Our code uses a minimal encoding of this metadata required. Specifically, you will need to tell our code about the types of your columns, and which column is the value to be predicted.\n",
    "\n",
    "Let's create some synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from BlackBoxAuditing.data import load_from_file\n",
    "\n",
    "iq = np.array(np.random.randn(20)) * 20 + 100\n",
    "gender = [random.choice([\"man\", \"woman\"]) for i in range(20)]\n",
    "sat = [i * 10 + (0 if g == \"man\" else 0) for (i, g) in zip(iq, gender)]\n",
    "admit = [\"True\" if s > 1100 else \"False\" for s in sat]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"admit\": admit,\n",
    "     \"gender\": gender,\n",
    "     \"iq\": iq,\n",
    "     \"sat\": sat})\n",
    "df.to_csv(\"/tmp/test.csv\", \n",
    "          index=False, \n",
    "          columns=['gender', 'admit', 'iq', 'sat']) # Make sure this order matches the order you're loading below\n",
    "synthetic_data = load_from_file(\"/tmp/test.csv\", correct_types = [str, str, float, float], response_header = 'admit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can audit this dataset with one of the existing classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = DecisionTree\n",
    "auditor(german_data, output_dir=\"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auditing your own model\n",
    "\n",
    "But what if you want to audit your own model? Here we show a very simple example of a (hard-coded) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BlackBoxAuditing.model_factories.AbstractModelFactory import AbstractModelFactory\n",
    "from BlackBoxAuditing.model_factories.AbstractModelVisitor import AbstractModelVisitor\n",
    "\n",
    "class SATPredictor(AbstractModelVisitor):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def test(self, test_set, test_name=\"\"):\n",
    "        return [(v[1], \"True\" if v[3] > 1100 else \"False\")\n",
    "                for v in test_set]\n",
    "class SATPredictorBuilder(AbstractModelFactory):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        AbstractModelFactory.__init__(self, *args, **kwargs)\n",
    "        self.verbose_factory_name = \"SATPredictor\"\n",
    "    def build(self, train_set):\n",
    "        return SATPredictor()\n",
    "    \n",
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = SATPredictorBuilder\n",
    "auditor(synthetic_data, output_dir=\"synthetic-audit-output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from BlackBoxAuditing.data import load_from_file\n",
    "\n",
    "\n",
    "np.random.seed(42)  # Set a random seed for reproducibility\n",
    "\n",
    "# Generate the features\n",
    "n_samples = 6000\n",
    "\n",
    "\n",
    "\n",
    "# Features directly encoding row number i\n",
    "A = np.arange(1, n_samples + 1)\n",
    "B = 2 * A\n",
    "B = B.tolist()\n",
    "C = -A\n",
    "C = C.tolist()\n",
    "\n",
    "# Random feature and constant feature\n",
    "Random = np.random.randn(n_samples) + 0.00001\n",
    "Random = Random.tolist()\n",
    "\n",
    "\n",
    "# Generate the labels\n",
    "admit = np.repeat([False, True], n_samples // 2)\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\"admit\": admit,\n",
    "    \"A\": A,\n",
    "    \"B\": B,\n",
    "    \"C\": C,\n",
    "    \"Random\": Random})\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"/tmp/test.csv\", index=False, columns = ['A','admit','B','C','Random'])\n",
    "\n",
    "# Load the synthetic data using BlackBoxAuditing\n",
    "synthetic_data = load_from_file(\"/tmp/test.csv\", correct_types=[float, str, float, float, float], response_header='admit')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = DecisionTree\n",
    "auditor(compass_data, output_dir=\"Test3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = DecisionTree\n",
    "auditor.RETRAIN_MODEL_PER_REPAIR = True\n",
    "auditor(synthetic_data, output_dir=\"synthetic-audit-output-DT-Retrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from BlackBoxAuditing.data import load_from_file\n",
    "\n",
    "\n",
    "np.random.seed(42)  # Set a random seed for reproducibility\n",
    "\n",
    "# Generate the features\n",
    "n_samples = 6000\n",
    "n_features = 5\n",
    "\n",
    "# Features directly encoding row number i\n",
    "A = np.arange(n_samples)\n",
    "B = 2 * A\n",
    "C = -A\n",
    "\n",
    "# Random feature and constant feature\n",
    "Random = np.random.randn(n_samples)\n",
    "Constant = np.ones(n_samples) + np.random.normal(0, 0.01, n_samples)  # Add small random noise\n",
    "\n",
    "# Concatenate the features into a numpy array\n",
    "features = np.column_stack((A, B, C, Random, Constant))\n",
    "\n",
    "# Generate the labels\n",
    "labels = np.array([False]*(n_samples//2) + [True]*(n_samples//2))\n",
    "\n",
    "\n",
    "# Replace NaN values with zeros\n",
    "features[np.isnan(features)] = 0.0\n",
    "\n",
    "# Create a dictionary with column names and data\n",
    "column_names = {\n",
    "    \"A\": A,\n",
    "    \"B\": B,\n",
    "    \"C\": C,\n",
    "    \"Random\": Random,\n",
    "    \"Constant\": Constant,\n",
    "    \"admit\": labels.astype(str)\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(column_names)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"/tmp/test.csv\", index=False)\n",
    "\n",
    "# Load the synthetic data using BlackBoxAuditing\n",
    "synthetic_data = load_from_file(\n",
    "    \"/tmp/test.csv\",\n",
    "    correct_types=[int, int, int, float, float, str],\n",
    "    response_header='admit'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = DecisionTree \n",
    "auditor.RETRAIN_MODEL_PER_REPAIR = True\n",
    "auditor(synthetic_data, output_dir=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import glob\n",
    "\n",
    "def search_keyword(keyword, folder_path):\n",
    "    file_pattern = folder_path + '/**/*.*'\n",
    "    \n",
    "    # Use glob to get a list of file paths matching the pattern\n",
    "    file_paths = glob.glob(file_pattern, recursive=True)\n",
    "    \n",
    "    # Use fileinput to iterate over the files and search for the keyword\n",
    "    for line in fileinput.input(file_paths):\n",
    "        if keyword in line:\n",
    "            print(f\"Match found in {fileinput.filename()} at line {fileinput.lineno()}: {line.strip()}\")\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"/Users/roccotrinci/Documents/Concordia Bachelor's/Honour's Project/New/auditing-tutorial/venv/lib/python3.10/site-packages/BlackBoxAuditing\"\n",
    "keyword = 'load_data'\n",
    "search_keyword(keyword, folder_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from BlackBoxAuditing.data import load_from_file\n",
    "\n",
    "\n",
    "# Generate the features\n",
    "n_samples = 6000\n",
    "n_features = 5\n",
    "\n",
    "# Features directly encoding row number i\n",
    "A = np.arange(n_samples)\n",
    "B = 2 * A\n",
    "C = -A\n",
    "\n",
    "# Random feature and constant feature\n",
    "Random = np.random.randn(n_samples)\n",
    "Constant = np.ones(n_samples) + np.random.normal(0, 0.01, n_samples)  # Add small random noise\n",
    "\n",
    "# Concatenate the features into a numpy array\n",
    "features = np.column_stack((A, B, C, Random, Constant))\n",
    "\n",
    "# Generate the labels\n",
    "labels = np.repeat([False, True], n_samples // 2)\n",
    "\n",
    "# Replace NaN values with zeros\n",
    "features[np.isnan(features)] = 0.0\n",
    "\n",
    "# Create a dictionary with column names and data\n",
    "column_names = {\n",
    "    \"A\": A,\n",
    "    \"B\": B,\n",
    "    \"C\": C,\n",
    "    \"Random\": Random,\n",
    "    \"Constant\": Constant,\n",
    "    \"admit\": labels.astype(str)\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(column_names)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"/tmp/test2.csv\", index=False)\n",
    "\n",
    "# Load the synthetic data using BlackBoxAuditing\n",
    "test_data = load_from_file(\n",
    "    \"/tmp/test2.csv\",\n",
    "    correct_types=[int, int, int, float, float, str],\n",
    "    response_header='admit'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = TensorFlow\n",
    "auditor(synthetic_data, output_dir=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_row = \"1 180 48 no 5 no 1 1 0 2 17.26 41.18 55.03 6.89 5.91 21.58 3.07 13.78 17.95 16.56 365.55 365.55 282.95 82.6 269.21 96.34 55.28 0 6 17.26 41.18 55.03 6.89 5.91 21.58 3.07 13.78 17.95 16.56 365.55 365.55 282.95 82.6 269.21 96.34 55.28 0 6 17.26 41.18 55.03 6.89 5.91 21.58 3.07 13.78 17.95 16.56 365.55 365.55 282.95 82.6 269.21 96.34 55.28 0 6 17.26 41.18 55.03 6.89 5.91 21.58 3.07 13.78 17.95 16.56 365.55 365.55 282.95 82.6 269.21 96.34 55.28 0 6 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 0.0597 0.0078 0 -0.047 7.6195 0.0676 no no no no no yes no no yes yes yes no no no no no no no no no no no no no no no no no no yes no no no no no no no yes no no no no no no no no no no no no no no no no no no yes no 684.3 71.9 2.16 378.1 306.2 190 684.3 71.9 2.16 378.1 306.2 190 684.3 71.9 2.16 378.1 306.2 190 684.3 71.9 2.16 378.1 306.2 190 2.4502 0.2574 0.0077 1.3538 1.0964 0.6803 2.4502 0.2574 0.0077 1.3538 1.0964 0.6803 2.4502 0.2574 0.0077 1.3538 1.0964 0.6803 2.4502 0.2574 0.0077 1.3538 1.0964 0.6803 1\"\n",
    "\n",
    "data_elements = data_row.split()\n",
    "data_row_types = []\n",
    "\n",
    "for element in data_elements:\n",
    "    try:\n",
    "        float(element)\n",
    "        data_row_types.append(\"float\")\n",
    "    except ValueError:\n",
    "        data_row_types.append(\"str\")\n",
    "\n",
    "           \n",
    "print(data_row_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_row_types[164] = 'float'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_row_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training initial model. (23:02:52)\n",
      "Calculating original model statistics on test data:\n",
      "\tTraining Set:\n",
      "\t\tConf-Matrix: {'A': {'A': 1989, 'B': 4}, 'B': {'B': 2006, 'A': 1}}\n",
      "\t\taccuracy: 0.99875\n",
      "\t\tBCR: 0.9987473596551558\n",
      "\tTesting Set:\n",
      "\t\tConf-Matrix {'A': {'A': 1006, 'B': 1}, 'B': {'B': 993}}\n",
      "\t\taccuracy: 0.9995\n",
      "\t\tBCR: 0.9995034756703078\n",
      "Auditing: 'Feature A (i)' (1/5). (23:02:52)\n",
      "repair level: \"0.0\"\n",
      "repair level: \"0.1\"\n",
      "repair level: \"0.2\"\n",
      "repair level: \"0.30000000000000004\"\n",
      "repair level: \"0.4\"\n",
      "repair level: \"0.5\"\n",
      "repair level: \"0.6\"\n",
      "repair level: \"0.7\"\n",
      "repair level: \"0.7999999999999999\"\n",
      "repair level: \"0.8999999999999999\"\n",
      "repair level: \"0.9999999999999999\"\n",
      "> \u001b[0;32m/Users/roccotrinci/Documents/Concordia Bachelor's/Honour's Project/New/auditing-tutorial/venv/lib/python3.10/site-packages/BlackBoxAuditing/repairers/CategoricRepairer.py\u001b[0m(118)\u001b[0;36mrepair\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    116 \u001b[0;31m    \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    117 \u001b[0;31m    \u001b[0;31m# Repair Data and retrieve the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 118 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mcol_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcols_to_repair\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    119 \u001b[0;31m      \u001b[0;31m# which bucket value we're repairing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    120 \u001b[0;31m      \u001b[0mgroup_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_stratified_groups\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "auditor = BBA.Auditor()\n",
    "auditor.ModelFactory = SVM\n",
    "auditor(synthetic_data, output_dir=\"RepairTest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
